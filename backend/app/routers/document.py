from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Dict, List, Optional, Any
import re
import base64
from openai import OpenAI
from ..core.config import get_settings
from ..utils.openai_helpers import analyze_document_with_assistant
import io

router = APIRouter(tags=["document"])
settings = get_settings()
client = OpenAI(api_key=settings.OPENAI_API_KEY)


class DocumentAnalysisRequest(BaseModel):
    image_data: Optional[str] = None  # Base64 encoded image
    image_url: Optional[str] = None   # Image URL (fallback for generated images)
    document_type: Optional[str] = None
    question: Optional[str] = None
    language: str = "hinglish"


class DocumentAnalysisResponse(BaseModel):
    success: bool
    analysis: Optional[Dict[str, Any]] = None
    answer: Optional[str] = None
    message: Optional[str] = None


class ImageGenerationRequest(BaseModel):
    prompt: str
    language: str = "hinglish"


class ImageGenerationResponse(BaseModel):
    success: bool
    image_url: Optional[str] = None
    message: Optional[str] = None


async def fetch_image_from_url(image_url: str) -> str:
    """Fetch image from URL and convert to base64"""
    try:
        import httpx
        
        print(f"ЁЯМР Fetching image from URL: {image_url}")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(image_url)
            response.raise_for_status()
            
            # Get image data
            image_data = response.content
            
            # Convert to base64
            base64_data = base64.b64encode(image_data).decode('utf-8')
            
            print(f"тЬЕ Successfully fetched and converted image ({len(image_data)} bytes)")
            return base64_data
            
    except Exception as e:
        print(f"тЭМ Error fetching image from URL: {e}")
        raise HTTPException(
            status_code=400, 
            detail=f"Failed to fetch image from URL: {str(e)}"
        )

async def generate_image_with_openai(prompt: str, language: str) -> str:
    """Generate image using OpenAI DALL-E API"""
    try:
        # Enhanced prompt for government-appropriate content
        if language == "hindi":
            enhanced_prompt = f"""рд╕рд░рдХрд╛рд░реА рдкреНрд░рд╕реНрддреБрддрд┐ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреБрдХреНрдд, рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдФрд░ рд╢рд┐рдХреНрд╖рд╛рдкреНрд░рдж рдЫрд╡рд┐: {prompt}ред 
            рд╕реНрд╡рдЪреНрдЫ, рд╕рд░рд▓ рдФрд░ рд╕реНрдкрд╖реНрдЯ рдбрд┐рдЬрд╝рд╛рдЗрдиред рдЧреНрд░рд╛рдореАрдг рднрд╛рд░рдд рдХреЗ рд╕рдВрджрд░реНрдн рдореЗрдВред рдкрд╛рд░рдВрдкрд░рд┐рдХ рд░рдВрдЧреЛрдВ рдХрд╛ рдЙрдкрдпреЛрдЧред"""
        else:
            enhanced_prompt = f"""Professional, educational image suitable for government presentation: {prompt}. 
            Clean, simple and clear design. In the context of rural India. Use traditional colors."""
        
        # Call OpenAI DALL-E API
        try:
            # Try DALL-E 3 first
            response = client.images.generate(
                model="dall-e-3",
                prompt=enhanced_prompt[:1000],  # DALL-E has prompt limits
                size="1024x1024",
                quality="standard",
                n=1
            )
            return response.data[0].url
        except Exception as e:
            # Fallback to DALL-E 2 if DALL-E 3 not available
            print(f"DALL-E 3 failed, trying DALL-E 2: {e}")
            try:
                response = client.images.generate(
                    model="dall-e-2",
                    prompt=enhanced_prompt[:1000],
                    size="1024x1024",
                    n=1
                )
                return response.data[0].url
            except Exception as e2:
                print(f"DALL-E 2 also failed: {e2}")
                raise HTTPException(
                    status_code=503, 
                    detail="Image generation service temporarily unavailable. Please try again later."
                )
        
    except Exception as e:
        print(f"Error in OpenAI image generation: {e}")
        # Return a government-themed placeholder
        if language == "hindi":
            placeholder_text = "рд╕рд░рдХрд╛рд░реА рдЗрдиреНрдлреЛрдЧреНрд░рд╛рдлрд┐рдХ"
        else:
            placeholder_text = "Government Infographic"
        
        return f"https://via.placeholder.com/1024x1024/2F855A/ffffff?text={placeholder_text.replace(' ', '%20')}"


def validate_image_prompt(prompt: str, language: str) -> Dict[str, Any]:
    """Validate image prompt for appropriate content"""
    # Check for inappropriate keywords
    inappropriate_keywords = [
        'violence', 'weapon', 'explicit', 'sexual', 'hate', 'discrimination',
        'рд╣рд┐рдВрд╕рд╛', 'рд╣рдерд┐рдпрд╛рд░', 'рдЕрд╢реНрд▓реАрд▓', 'рдпреМрди', 'рдШреГрдгрд╛', 'рднреЗрджрднрд╛рд╡'
    ]
    
    prompt_lower = prompt.lower()
    for keyword in inappropriate_keywords:
        if keyword in prompt_lower:
            return {
                "is_appropriate": False,
                "reason": "Inappropriate content detected" if language == "hinglish" 
                         else "рдЕрдиреБрдЪрд┐рдд рд╕рд╛рдордЧреНрд░реА рдХрд╛ рдкрддрд╛ рдЪрд▓рд╛",
                "suggestion": "Please provide a description suitable for government/educational content" 
                            if language == "hinglish" 
                            else "рдХреГрдкрдпрд╛ рд╕рд░рдХрд╛рд░реА/рд╢реИрдХреНрд╖рдгрд┐рдХ рд╕рд╛рдордЧреНрд░реА рдХреЗ рд▓рд┐рдП рдЙрдкрдпреБрдХреНрдд рд╡рд┐рд╡рд░рдг рдкреНрд░рджрд╛рди рдХрд░реЗрдВ"
            }
    
    return {
        "is_appropriate": True,
        "enhanced_prompt": prompt
    }


@router.post("/document", response_model=DocumentAnalysisResponse)
async def analyze_document(request: DocumentAnalysisRequest):
    """
    Analyze uploaded documents using OpenAI Vision API
    """
    try:
        print(f"ЁЯУе Document analysis request received")
        print(f"ЁЯМН Language: {request.language}")
        print(f"ЁЯУЛ Has image_data: {bool(request.image_data)}")
        print(f"ЁЯМР Has image_url: {bool(request.image_url)}")
        print(f"ЁЯУС Document type: {request.document_type}")
        print(f"тЭУ Question: {request.question}")
        
        language = request.language or "hinglish"
        
        # Handle both image_data (base64) and image_url cases
        image_data = None
        
        if request.image_data:
            print("ЁЯУЛ Using provided base64 image data")
            print(f"ЁЯУК Image data length: {len(request.image_data)} characters")
            image_data = request.image_data
        elif request.image_url:
            print("ЁЯМР Fetching image from URL")
            print(f"ЁЯФЧ URL: {request.image_url}")
            image_data = await fetch_image_from_url(request.image_url)
        else:
            print("тЭМ No image data or URL provided")
            return DocumentAnalysisResponse(
                success=False,
                message="No image data or URL provided" if language == "hinglish" 
                       else "рдХреЛрдИ рдЫрд╡рд┐ рдбреЗрдЯрд╛ рдпрд╛ URL рдкреНрд░рджрд╛рди рдирд╣реАрдВ рдХрд┐рдпрд╛ рдЧрдпрд╛"
            )
        
        # Analyze document using OpenAI Assistant
        print(f"ЁЯОп Starting document analysis with Assistant API...")
        analysis_result = await analyze_document_with_assistant(
            file_data_base64=image_data, 
            language=language, 
            question=request.question
        )
        print(f"тЬЕ Analysis completed successfully")
        print(f"ЁЯУЛ Result type: {analysis_result.get('document_type', 'Unknown')}")
        print(f"ЁЯУЭ Main info: {analysis_result.get('main_information', 'No info')[:100]}...")
        
        # The answer is now part of the main_information from the assistant
        answer = analysis_result.get('main_information')

        response = DocumentAnalysisResponse(
            success=True,
            analysis=analysis_result,
            answer=answer,
            message="Document analyzed successfully" if language == "hinglish" 
                   else "рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рд╕рдлрд▓рддрд╛рдкреВрд░реНрд╡рдХ рдкреВрд░рд╛ рд╣реБрдЖ"
        )
        
        print(f"ЁЯУд Sending successful response")
        return response

    except Exception as e:
        print(f"тЭМ Error in document analysis endpoint: {type(e).__name__}: {str(e)}")
        error_msg = f"Error analyzing document: {str(e)}"
        return DocumentAnalysisResponse(
            success=False, 
            message=error_msg if request.language == "hinglish" 
                   else f"рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдореЗрдВ рддреНрд░реБрдЯрд┐: {str(e)}"
        )


@router.post("/generate-image", response_model=ImageGenerationResponse)
async def generate_image(request: ImageGenerationRequest):
    """
    Generate infographic/image using OpenAI DALL-E API
    """
    try:
        # Validate prompt
        validation = validate_image_prompt(request.prompt, request.language)
        
        if not validation["is_appropriate"]:
            return ImageGenerationResponse(
                success=False,
                message=f"{validation['reason']}. {validation['suggestion']}"
            )
        
        # Generate image using OpenAI DALL-E
        image_url = await generate_image_with_openai(request.prompt, request.language)
        
        return ImageGenerationResponse(
            success=True,
            image_url=image_url,
            message="Image generated successfully" if request.language == "hinglish" 
                   else "рдЫрд╡рд┐ рд╕рдлрд▓рддрд╛рдкреВрд░реНрд╡рдХ рдмрдирд╛рдИ рдЧрдИ"
        )

    except Exception as e:
        error_msg = f"Error generating image: {str(e)}"
        return ImageGenerationResponse(
            success=False, 
            message=error_msg if request.language == "hinglish" 
                   else f"рдЫрд╡рд┐ рдмрдирд╛рдиреЗ рдореЗрдВ рддреНрд░реБрдЯрд┐: {str(e)}"
        ) 